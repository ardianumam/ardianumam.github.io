<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%91%E2%80%8D%F0%9F%92%BB&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ardianumam.github.io/partdistill/"> <script src="/assets/js/theme.js?da223b2b423d03c8b9950d3e6131194c"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=yes"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>PartDistill (CVPR 2024)</title> <nav class="project-page-nav"> <ul style="margin: 0.3rem"> <li style="display: inline-block;"> <div class="project-page-home-button"> <a href="https://ardianumam.github.io" target="_self" class="hyperlink"> <i class="fas fa-home home-icon"></i> </a> </div> </li> <li style="display: inline-block;"> <button id="back-to-top" class="project-page-home-button"> <i class="fas fa-arrow-up"></i> </button> </li> <li style="display: inline-block;"> <div class="theme-container"> <button id="theme-button" style="padding: 10px 10px;" title="Change theme"> <i class="fas fa-lightbulb"></i> </button> <div class="theme-options"> <button id="light-button"> <i class="ti ti-sun-filled" id="light-icon"></i> (light) </button> <button id="dark-button"> <i class="ti ti-moon-filled" id="dark-icon"></i> (dark) </button> </div> </div> </li> </ul> </nav> <p><br></p> <div class="container research"> <h1 style="text-align: center; font-weight: bold; margin-bottom:0.9rem;">PartDistill: 3D Shape Part Segmentation by Vision-Language Model Distillation</h1> <div class="author"> <a href="https://ardianumam.github.io/">Ardian Umam<sup>1</sup></a> <a href="https://scholar.google.com/citations?user=Ke4_ozgAAAAJ&amp;hl=en&amp;oi=sra" rel="external nofollow noopener" target="_blank">Cheng-Kun Yang<sup>2</sup></a> <a href="https://minhungchen.netlify.app/" rel="external nofollow noopener" target="_blank">Min-Hung Chen<sup>3</sup></a> <a href="https://www.cs.nycu.edu.tw/members/detail/jchuang" rel="external nofollow noopener" target="_blank">Jen-Hui Chuang<sup>1</sup></a> <a href="https://sites.google.com/site/yylinweb/" rel="external nofollow noopener" target="_blank">Yen-Yu Lin<sup>2</sup></a> </div> <div class="author"> <sup>1</sup>National Yang Ming Chiao Tung University <sup>2</sup>MediaTek <sup>3</sup>NVIDIA</div> <h4 style="text-align: center; font-weight: bold; margin-top: 0.9rem">CVPR 2024</h4> <div class="container text-center"> <div class="column has-text-centered"> <a href="https://arxiv.org/abs/2312.04016" class="hyperlink-button" rel="external nofollow noopener" target="_blank"> <span class="hyperlink-button-text">Paper</span> <i class="ai ai-arxiv"></i> </a> <a href="#" class="hyperlink-button"> <span class="hyperlink-button-text">Poster</span> <i class="fa fa-file-pdf"></i> </a> <a href="https://github.com/ardianumam/PartDistill" class="hyperlink-button" rel="external nofollow noopener" target="_blank"> <span class="hyperlink-button-text">Code</span> <i class="fab fa-github"></i> </a> <a href="#" class="hyperlink-button"> <span class="hyperlink-button-text">Video</span> <i class="fas fa-video"></i> </a> </div> </div> <br><br> <h2 style="text-align: center;">Abstract</h2> <div class="content"> We propose a cross-modal distillation framework, PartDistill, which transfers 2D knowledge from vision-language models (VLMs) to facilitate 3D shape part segmentation. PartDistill addresses three major issues in this task, namely \(\boldsymbol{\mathcal{I}_1}\): the lack of 3D segmentation in invisible or undetected regions in the 2D projections, \(\boldsymbol{\mathcal{I}_2}\): inconsistent 2D predictions by VLMs, and \(\boldsymbol{\mathcal{I}_3}\): the lack of knowledge accumulation across different 3D shapes. PartDistill consists of a teacher network that uses a VLM to make 2D predictions and a student network that learns from the 2D predictions while extracting geometrical features from multiple 3D shapes to carry out 3D part segmentation. A bidirectional distillation, including forward and backward distillations, is carried out within the framework, where the former forward distills the 2D predictions to the student network, and the latter improves the quality of the 2D predictions, which subsequently enhances the final 3D segmentation. Moreover, PartDistill can exploit generative models that facilitate effortless 3D shape creation for generating knowledge sources to be distilled. Through extensive experiments, PartDistill boosts the existing methods with substantial margins on widely used ShapeNetPart and PartNetE datasets, by more than 15% and 12% higher mIoU scores, respectively. </div> <br> <h2 style="text-align: center;">Method</h2> <img src="/assets/img/project_page/2024_partdistill/main_fig.png" alt="Architecture of PartDistill" class="img-fluid mx-auto d-block"> <div class="content" style="margin-top: 1rem"> <b>Overview of the proposed method.</b> (a) The overall pipeline where the knowledge extracted from a vision-language model (VLM) is distilled to carry out 3D shape part segmentation by teaching a 3D student network. Within the pipeline, <em>backward distillation</em> is introduced to re-score the teacherâ€™s knowledge based on its quality and subsequently improve the final 3D part prediction. (b) &amp; (c) Knowledge is extracted by back-projection when we adopt (b) a bounding-box VLM (B-VLM) or (c) a pixel-wise VLM (P-VLM). </div> <br> <h2 style="text-align: center;">Experimental Results</h2> <h4 style="text-align: center;">Qualitative results</h4> <img src="/assets/img/project_page/2024_partdistill/qualitative_result.png" alt="Qualitative results" class="img-fluid mx-auto d-block"> <div class="content" style="margin-top: 1rem"> Visualization of the zero-shot segmentation results, drawn in different colors, on the ShapeNetPart dataset. We render PartSLIP results on the ShapeNetPart data to have the same visualization of shape inputs. While issue \(\boldsymbol{\mathcal{I}_1}\): occluded and undetected regions are shown with black and gray colors, respectively, the blue and red arrows highlight several cases of issues \(\boldsymbol{\mathcal{I}_2}\): negative transfer and \(\boldsymbol{\mathcal{I}_3}\): lack of knowledge accumulation. </div> <br> <h4 style="text-align: center;">Quantitative results</h4> <img src="/assets/img/project_page/2024_partdistill/quantitative_result1.png" alt="Quantitative results" class="img-fluid mx-auto d-block"> <div class="content" style="margin-top: 1rem"> We carry out the comparison separately to ensure fairness, based on the employed VLM model and the shape data type, i.e., point cloud or mesh data, as shown in above tables. In the upper table, we provide two versions of our method, including test-time alignment (TTA) and prealignment (Pre) with a collection of shapes from the trainset data, while in the lower table, only TTA version is provided since the PartNetE dataset does not provide train-set data. From the tables, our method demonstrates its consistency on surpassing the benchmark methods. </div> <img src="/assets/img/project_page/2024_partdistill/quantitative_result2.png" alt="Quantitative results" class="img-fluid mx-auto d-block"> <div class="content" style="margin-top: 1rem"> Regarding leveraging generative models, if a collection of shapes does not exist, generative models can be employed for shape creation and subsequently used in our method as the knowledge source. From the table above, such approach (second row) achieves competitive results compared to distilling from the train-set data (first row). Furthermore, when a collection of shapes is available, generated data can be employed as supplementary knowledge sources, which can improve the performance (third row). </div> <br> <h3>Acknowledgment</h3> <div class="content" style="margin-top: 1rem"> This work was supported in part by the National Science and Technology Council (NSTC) under grants 112-2221-E-A49-090-MY3, 111-2628-E-A49-025-MY3, 112-2634-F-006-002 and 112-2634-F-A49-007. This work was funded in part by MediaTek and NVIDIA. </div> <br> <h4>BibTeX</h4> <div class="bibtex-container"> <pre id="bibtex">@inproceedings{umam2023partdistill,
      title = {PartDistill: 3D Shape Part Segmentation by Vision-Language Model Distillation},
      author = {Umam, Ardian and Yang, Cheng-Kun and Chen, Min-Hung and Chuang, Jen-Hui and Lin, Yen-Yu},
      booktitle = {IEEE/CVF International Conference on Computer Vision (CVPR)},
      year = {2024},
}</pre> <button onclick="copyBibtex()" class="copy-btn"> <i class="fas fa-copy"></i> </button> </div> </div> <script>function copyBibtex(){var o=document.getElementById("bibtex").innerText;navigator.clipboard.writeText(o).then(()=>{var o=document.querySelector(".copy-btn i");o.classList.remove("fa-copy"),o.classList.add("fa-clipboard-check"),setTimeout(()=>{o.classList.remove("fa-clipboard-check"),o.classList.add("fa-copy")},2e3)})["catch"](o=>console.error("Error copying BibTeX: ",o))}const backToTopButton=document.getElementById("back-to-top");backToTopButton.addEventListener("click",()=>{window.scrollTo({top:0,behavior:"smooth"})});</script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>